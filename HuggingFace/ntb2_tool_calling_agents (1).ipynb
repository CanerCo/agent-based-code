{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALra7BONbKAr"
      },
      "outputs": [],
      "source": [
        "# First pip install smolagents\n",
        "!pip install smolagents -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the dependencies and login to HF account to access the Inference API\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "9ROHXop6bd8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# THE TOOL DECORATORS\n",
        "Generating a tool that retrieves the highest-rated restaurants in Berlin.\n",
        "\n",
        "We will create an example of how we can use @tool decorator to find out best restaurant in Berlin."
      ],
      "metadata": {
        "id": "AzJ45uAMbniz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from smolagents import CodeAgent, InferenceClientModel, tool\n",
        "\n",
        "# Let's pretend we have a function that fetches the highest-rated restaurant services.\n",
        "\n",
        "\n",
        "@tool\n",
        "def restaurant_service_tool(query: str) -> str:\n",
        "  \"\"\"\n",
        "  This tool returns the highest rated restaurant service in Berlin.\n",
        "\n",
        "  Args:\n",
        "      query: A search term for finding restaurant services\n",
        "  \"\"\"\n",
        "  # Example list of restaurants and their ratings\n",
        "  restaurants = {\n",
        "      \"Restaurant-1\":4.9,\n",
        "      \"Resturant-2\":4.7,\n",
        "      \"McDonalds\":4.1,\n",
        "      \"Starbucks\":3.7,\n",
        "      \"Restaurant-3\": 4.8\n",
        "  }\n",
        "  # Find the highest rated rest. (simulating search query filtering)\n",
        "  best_restaurant = max(restaurants, key=restaurants.get)\n",
        "\n",
        "  return best_restaurant\n",
        "\n",
        "agent = CodeAgent(\n",
        "    tools=[restaurant_service_tool],\n",
        "    model=InferenceClientModel()\n",
        ")\n",
        "\n",
        "# Run the Agent to find the best restaurant.\n",
        "result = agent.run(\n",
        "    \"Can you give me the name of the highest rated restaurant service in Berlin City?\"\n",
        ")\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "r9GNTwZEblkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining a Tool as Python Class\n",
        "\n",
        "Generating a tool to generate ideas about the phd ideas\n",
        "\n",
        "Alfred needs some creative ideas to make it special.\n",
        "\n",
        "To do this, he can use an agent that generates phd ideas  based on a given category."
      ],
      "metadata": {
        "id": "OyUXcUwndXK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from smolagents import Tool, CodeAgent, InferenceClientModel\n",
        "\n",
        "class PhdIdeasTopicTool(Tool):\n",
        "  name = \"phd_ideas_generator\"\n",
        "  description = \"\"\"\n",
        "  This tool suggests creative phd ideas based on category.\n",
        "  It returns a unique phd idea.\"\"\"\n",
        "\n",
        "  inputs = {\n",
        "      \"category\":{\n",
        "          \"type\":\"string\",\n",
        "          \"description\":\"The type of phd Idea (e.g, 'computational Linguistics', 'Natural Language Processing', 'Computer-science related (more technical)')\"\n",
        "      }\n",
        "  }\n",
        "\n",
        "  output_type = \"string\"\n",
        "\n",
        "  def forward(self, category: str):\n",
        "    themes = {\n",
        "        \"computational linguistics:This category has more linguistics elements with enough computational side\",\n",
        "        \"Natural Language Processing: This is related to modern NLP tasks and ML algorithms\",\n",
        "        \"Computer Science: This is more in the technical side rather than relevant to linguistics aspects of NLP.\"\n",
        "    }\n",
        "\n",
        "    return themes.get(category.lower(), \"Themed phd idea not found. Try 'computational linguistics', 'Natural Langauge Processing', or 'Computer Science'\")\n",
        "\n",
        "# Instantiate the tool\n",
        "phd_idea_tool = PhdIdeasTopicTool()\n",
        "agent = CodeAgent(tools=[phd_idea_tool], model=InferenceClientModel())\n",
        "# run the agent to generate a phd idea with a specific category.\n",
        "result = agent.run(\n",
        "    \"What would be a good phd idea for a computational linguistics theme?\"\n",
        ")\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "-scjCuTidg-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sharing a tool the hub\n",
        "\n",
        "Sharing your custom tool with the community is easy! Simply upload it to your Hugging Face account using the push_to_hub() method.\n",
        "\n",
        "For instance, Alfred can share his catering_service_tool to help others find the best catering services in Gotham. Here's how to do it:"
      ],
      "metadata": {
        "id": "dhmGxpcyj2wO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "phd_idea_tool.push_to_hub(\"CanerCoban/phd_ideas_tool\", token=\"MYHFtOKEN\")"
      ],
      "metadata": {
        "id": "Vfv1zVzqdjiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing a Tool from the Hub\n",
        "\n",
        "You can easily import tools created by other users using the load_tool() function.\n",
        "\n",
        "Instead of building a tool form scratch, we can use a predefined one from the community"
      ],
      "metadata": {
        "id": "qvG_36UzkZuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from smolagents import load_tool, CodeAgent, InferenceClientModel\n",
        "\n",
        "image_generation_tool = load_tool(\n",
        "    \"m-ric/text-to-image\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "agent = CodeAgent(\n",
        "    tools=[image_generation_tool],\n",
        "    model=InferenceClientModel()\n",
        ")\n",
        "\n",
        "agent.run(\"Generate an image of graduate student looking for phd jobs.\")"
      ],
      "metadata": {
        "id": "s-W-L2btkk-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing a HuggingFace as a tool\n",
        "We can import a HF Space as a tool using Tool.from_space().\n",
        "\n",
        "\n",
        "Opens up possibilities for integrating with thousands of spaces from the community for tasks from image generation to data analysis."
      ],
      "metadata": {
        "id": "ptITrD0Ik6bv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The tool will connect with the spaces Gradio backend using the gradio_client\n",
        "# we need to make sure that gradio is installed via pip.\n",
        "!pip install gradio_client"
      ],
      "metadata": {
        "id": "zv2peW6OlCpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from smolagents import CodeAgent, InferenceClientModel, Tool\n",
        "\n",
        "image_generation_tool = Tool.from_space(\n",
        "    \"black-forest-labs/FLUX.1-schnell\",\n",
        "    name=\"image_generator\",\n",
        "    description=\"Generate an image from a prompt\"\n",
        ")\n",
        "\n",
        "model = InferenceClientModel(\"Qwen/Qwen2.5-Coder-32B-Instruct\")\n",
        "\n",
        "agent = CodeAgent(tools=[image_generation_tool],model=model)\n",
        "\n",
        "agent.run(\"Improve this prompt, then generate an image of it.\",\n",
        "          additional_args={'user_prompt': 'A graduate student looking for phd positions to apply.'}\n",
        "          )"
      ],
      "metadata": {
        "id": "9Q3D_Yr1lGk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image as PILImage\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_path = '/tmp/gradio/ee85723f43a3b52e4b0f8656204aefd908298d0577c71647607732c1cf073314/image.webp'\n",
        "\n",
        "img = PILImage.open(image_path)\n",
        "img"
      ],
      "metadata": {
        "id": "XzHPaizmlU7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing a Langchain tool\n",
        "\n",
        "These ttols need a (https://serpapi.com/) Google Search API key.\n",
        "\n",
        "You can easily load LangChain tools using the Tool.from_langchain() method.\n",
        "\n",
        "We need to tap into LangChain tools to find top-tier entertainment tools.\n",
        "\n",
        "\n",
        "By using Tool.from_langchain(), we add search functionalities to our smolagents, enable us to discover exclusive party ideas and services with just a few commands.\n",
        "\n",
        "Here is how we do it:"
      ],
      "metadata": {
        "id": "Opn7NZFhlbV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community google-search-results"
      ],
      "metadata": {
        "id": "N6HzTD6WlhZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ[\"SERPAPI_API_KEY\"] = userdata.get(\"SEARCH_API\")"
      ],
      "metadata": {
        "id": "wBNBLdV5li58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools\n",
        "from smolagents import CodeAgent, InferenceClientModel, Tool\n",
        "\n",
        "search_tool = Tool.from_langchain(load_tools([\"serpapi\"])[0])\n",
        "\n",
        "agent = CodeAgent(tools=[search_tool], model=model)\n",
        "\n",
        "agent.run(\"Search for phd ideas for a computational linguist graduate student\")\n"
      ],
      "metadata": {
        "id": "5MBlko2MltTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing a tool collection from any MCP server\n",
        "\n",
        " smolagents also allows importing tools from the hundreds of MCP servers available on glama.ai or smithery.ai."
      ],
      "metadata": {
        "id": "0w2ZA6W6mV7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install mcp client\n",
        "# We first need to install the mcp integration for smolagents\n",
        "!pip install \"smolagents[mcp]\""
      ],
      "metadata": {
        "id": "pejrWC96mekj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The MCP server tools can be loaded in a ToolCollecttion object as follow:\n",
        "import os\n",
        "from smolagents import ToolCollection, CodeAgent\n",
        "from mcp import StdioServerParameters\n",
        "from smolagents import InferenceClientModel\n",
        "\n",
        "\n",
        "model = InferenceClientModel(\"Qwen/Qwen2.5-Coder-32B-Instruct\")\n",
        "\n",
        "\n",
        "server_parameters = StdioServerParameters(\n",
        "    command=\"uvx\",\n",
        "    args=[\"--quiet\", \"pubmedmcp@0.1.3\"],\n",
        "    env={\"UV_PYTHON\": \"3.12\", **os.environ},\n",
        ")\n",
        "\n",
        "with ToolCollection.from_mcp(server_parameters, trust_remote_code=True) as tool_collection:\n",
        "    agent = CodeAgent(tools=[*tool_collection.tools], model=model, add_base_tools=True)\n",
        "    agent.run(\"Please find a remedy for hangover.\")"
      ],
      "metadata": {
        "id": "TEMZTFo2mh-J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}